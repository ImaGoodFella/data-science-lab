{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b83513a-3d6a-477a-b5e9-d7160b8a9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c7365dc-63ea-43fc-b839-7cef886e18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(path, dataset, seed):\n",
    "\n",
    "    dataset_path = f'../data/{dataset}.csv' if dataset=='expert' else f'../data/{dataset}_{seed}.csv'\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    \n",
    "    with open(path, 'rb') as f:\n",
    "        res_vals = pickle.load(f)\n",
    "        \n",
    "    df.loc[res_vals['idx'], 'labels'] = res_vals['labels']\n",
    "    df.loc[res_vals['idx'], 'predictions'] = res_vals['predictions']\n",
    "    df.loc[res_vals['idx'], 'neg_prob'] = res_vals['probabilities'][:,0]\n",
    "    df.loc[res_vals['idx'], 'pos_prob'] = res_vals['probabilities'][:,1]\n",
    "    \n",
    "    if dataset=='expert':\n",
    "        df['labels'] = (df['labels'].astype(bool) & ~df['Konsensus Target 1'].isna()).astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "262707fc-9394-495a-9161-caa079d6c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, labels):\n",
    "    \n",
    "    res = []\n",
    "\n",
    "    res.append(balanced_accuracy_score(predictions, labels))\n",
    "    res.append(f1_score(predictions, labels, average='binary'))\n",
    "    res.append(precision_score(predictions, labels, average='binary'))\n",
    "    res.append(recall_score(predictions, labels, average='binary'))\n",
    "    res.append(f1_score(1 - predictions, 1 - labels, average='binary'))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55154832-b460-429b-bc17-9c8fd7986a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d33a31b-1b69-43d2-81aa-d3e6eaf65a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasteiger/miniconda3/envs/dslab/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/rasteiger/miniconda3/envs/dslab/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(columns=['model_name', 'optimizer', 'class_weights', 'batch_size', 'seed', 'dataset', 'balanced_accuracy', 'f1', 'precision', 'recall', 'f1_neg'])\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        try:\n",
    "            info = subdir.split('/')\n",
    "            model_name = info[3]\n",
    "            optimizer = info[4]\n",
    "            class_weights = info[5][-1] == '1'\n",
    "            batch_size = int(info[6][-2:])\n",
    "            seed = int(info[7][-2:])\n",
    "            dataset = file[:-12]\n",
    "            df = get_results(os.path.join(subdir, file), dataset, seed)\n",
    "            params = [model_name, optimizer, class_weights, batch_size, seed, dataset]\n",
    "            metrics = calculate_metrics(df['predictions'], df['labels'])\n",
    "            df_results.loc[len(df_results)] = params + metrics\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59987466-26e8-43e7-9794-f5ed223dac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>class_weights</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>dataset</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.760465</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.855072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e5</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.857550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>e5_lora_nli_all</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.752870</td>\n",
       "      <td>0.655518</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.853067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>e5_lora_nli_all</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.750476</td>\n",
       "      <td>0.651007</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e5</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.750484</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.852691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>e5no_train</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>test</td>\n",
       "      <td>0.178134</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178134</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>e5no_train</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.517904</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>e5no_train</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>expert</td>\n",
       "      <td>0.552068</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.799499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>e5no_train</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>test</td>\n",
       "      <td>0.527567</td>\n",
       "      <td>0.197960</td>\n",
       "      <td>0.176360</td>\n",
       "      <td>0.225590</td>\n",
       "      <td>0.848709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>e5no_train</td>\n",
       "      <td>adamw</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>test</td>\n",
       "      <td>0.494679</td>\n",
       "      <td>0.183416</td>\n",
       "      <td>0.199515</td>\n",
       "      <td>0.169721</td>\n",
       "      <td>0.803742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_name optimizer  class_weights  batch_size  seed dataset  \\\n",
       "3                e5     adamw           True          16    42  expert   \n",
       "1                e5     adamw           True          16    43  expert   \n",
       "51  e5_lora_nli_all     adamw           True          16    43  expert   \n",
       "53  e5_lora_nli_all     adamw           True          16    44  expert   \n",
       "5                e5     adamw           True          16    44  expert   \n",
       "..              ...       ...            ...         ...   ...     ...   \n",
       "64       e5no_train     adamw           True          16    44    test   \n",
       "63       e5no_train     adamw           True          16    43  expert   \n",
       "61       e5no_train     adamw           True          16    42  expert   \n",
       "60       e5no_train     adamw           True          16    42    test   \n",
       "62       e5no_train     adamw           True          16    43    test   \n",
       "\n",
       "    balanced_accuracy        f1  precision    recall    f1_neg  \n",
       "3            0.760465  0.677419   0.709459  0.648148  0.855072  \n",
       "1            0.760000  0.664430   0.668919  0.660000  0.857550  \n",
       "51           0.752870  0.655518   0.662162  0.649007  0.853067  \n",
       "53           0.750476  0.651007   0.655405  0.646667  0.851852  \n",
       "5            0.750484  0.646259   0.641892  0.650685  0.852691  \n",
       "..                ...       ...        ...       ...       ...  \n",
       "64           0.178134  0.302400   1.000000  0.178134  0.000000  \n",
       "63           0.517904  0.273438   0.236486  0.324074  0.750000  \n",
       "61           0.552068  0.207921   0.141892  0.388889  0.799499  \n",
       "60           0.527567  0.197960   0.176360  0.225590  0.848709  \n",
       "62           0.494679  0.183416   0.199515  0.169721  0.803742  \n",
       "\n",
       "[66 rows x 11 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "044aff03-9a4f-493a-be82-d5199d485a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">balanced_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>class_weights</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.662702</td>\n",
       "      <td>0.015652</td>\n",
       "      <td>0.673423</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.652944</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.855105</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_lora_nli_all</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.749664</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.648660</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.650901</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.646503</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.851592</td>\n",
       "      <td>0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_lora_nli</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.749213</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.643199</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.637387</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.649695</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>0.851845</td>\n",
       "      <td>0.005916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_nli_all</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.732539</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.629306</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.509258</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.887340</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5_nli</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.733405</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.628909</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.637387</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.620996</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.840921</td>\n",
       "      <td>0.008852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.732655</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.628682</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.817133</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.510866</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.888123</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_nli_all</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.728035</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.623191</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.611957</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>0.837210</td>\n",
       "      <td>0.004208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.726756</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.622947</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.845898</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.493044</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.879669</td>\n",
       "      <td>0.003309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">roberta</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.734335</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.622677</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>0.617117</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>0.628421</td>\n",
       "      <td>0.010305</td>\n",
       "      <td>0.843399</td>\n",
       "      <td>0.004369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.723662</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.618079</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.844642</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.487360</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.877106</td>\n",
       "      <td>0.002119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_lora_nli</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.722646</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.617157</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.853213</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.483430</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>0.874895</td>\n",
       "      <td>0.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_lora</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.735082</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.616428</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.599099</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.634816</td>\n",
       "      <td>0.019259</td>\n",
       "      <td>0.845113</td>\n",
       "      <td>0.007654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_lora_nli_all</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.721535</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.615646</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.856579</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.480503</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.873353</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5_lora</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.719894</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.612951</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.855098</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.477686</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.871999</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">roberta_lora</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.715759</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.604925</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.834590</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.474428</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert</th>\n",
       "      <td>0.732715</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.602897</td>\n",
       "      <td>0.029906</td>\n",
       "      <td>0.572072</td>\n",
       "      <td>0.040728</td>\n",
       "      <td>0.637696</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.007093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.710856</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.596025</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.818525</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.468640</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.869165</td>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_lora</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>test</th>\n",
       "      <td>0.704566</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.585215</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.459442</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.865178</td>\n",
       "      <td>0.002841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.700776</td>\n",
       "      <td>0.010748</td>\n",
       "      <td>0.519386</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.452703</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>0.609243</td>\n",
       "      <td>0.017863</td>\n",
       "      <td>0.832878</td>\n",
       "      <td>0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_lora</th>\n",
       "      <th>adamw</th>\n",
       "      <th>True</th>\n",
       "      <th>16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.679901</td>\n",
       "      <td>0.027005</td>\n",
       "      <td>0.467693</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.389640</td>\n",
       "      <td>0.023729</td>\n",
       "      <td>0.584908</td>\n",
       "      <td>0.044441</td>\n",
       "      <td>0.825648</td>\n",
       "      <td>0.011633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5no_train</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>0.455324</td>\n",
       "      <td>0.139032</td>\n",
       "      <td>0.312716</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.470505</td>\n",
       "      <td>0.336321</td>\n",
       "      <td>0.047640</td>\n",
       "      <td>0.516500</td>\n",
       "      <td>0.447986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.400127</td>\n",
       "      <td>0.192953</td>\n",
       "      <td>0.227925</td>\n",
       "      <td>0.064906</td>\n",
       "      <td>0.458625</td>\n",
       "      <td>0.468987</td>\n",
       "      <td>0.191148</td>\n",
       "      <td>0.030123</td>\n",
       "      <td>0.550817</td>\n",
       "      <td>0.477551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           balanced_accuracy  \\\n",
       "                                                                        mean   \n",
       "model_name      optimizer class_weights batch_size dataset                     \n",
       "e5              adamw     True          16         expert           0.756983   \n",
       "e5_lora_nli_all adamw     True          16         expert           0.749664   \n",
       "e5_lora_nli     adamw     True          16         expert           0.749213   \n",
       "e5_nli_all      adamw     True          16         test             0.732539   \n",
       "e5_nli          adamw     True          16         expert           0.733405   \n",
       "                                                   test             0.732655   \n",
       "e5_nli_all      adamw     True          16         expert           0.728035   \n",
       "e5              adamw     True          16         test             0.726756   \n",
       "roberta         adamw     True          16         expert           0.734335   \n",
       "                                                   test             0.723662   \n",
       "e5_lora_nli     adamw     True          16         test             0.722646   \n",
       "e5_lora         adamw     True          16         expert           0.735082   \n",
       "e5_lora_nli_all adamw     True          16         test             0.721535   \n",
       "e5_lora         adamw     True          16         test             0.719894   \n",
       "roberta_lora    adamw     True          16         test             0.715759   \n",
       "                                                   expert           0.732715   \n",
       "bert            adamw     True          16         test             0.710856   \n",
       "bert_lora       adamw     True          16         test             0.704566   \n",
       "bert            adamw     True          16         expert           0.700776   \n",
       "bert_lora       adamw     True          16         expert           0.679901   \n",
       "e5no_train      adamw     True          16         expert           0.455324   \n",
       "                                                   test             0.400127   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 std   \n",
       "model_name      optimizer class_weights batch_size dataset             \n",
       "e5              adamw     True          16         expert   0.005633   \n",
       "e5_lora_nli_all adamw     True          16         expert   0.003680   \n",
       "e5_lora_nli     adamw     True          16         expert   0.007365   \n",
       "e5_nli_all      adamw     True          16         test     0.000528   \n",
       "e5_nli          adamw     True          16         expert   0.013359   \n",
       "                                                   test     0.003049   \n",
       "e5_nli_all      adamw     True          16         expert   0.004125   \n",
       "e5              adamw     True          16         test     0.003395   \n",
       "roberta         adamw     True          16         expert   0.007790   \n",
       "                                                   test     0.002738   \n",
       "e5_lora_nli     adamw     True          16         test     0.002969   \n",
       "e5_lora         adamw     True          16         expert   0.013629   \n",
       "e5_lora_nli_all adamw     True          16         test     0.001058   \n",
       "e5_lora         adamw     True          16         test     0.003162   \n",
       "roberta_lora    adamw     True          16         test     0.002737   \n",
       "                                                   expert   0.014986   \n",
       "bert            adamw     True          16         test     0.002028   \n",
       "bert_lora       adamw     True          16         test     0.003649   \n",
       "bert            adamw     True          16         expert   0.010748   \n",
       "bert_lora       adamw     True          16         expert   0.027005   \n",
       "e5no_train      adamw     True          16         expert   0.139032   \n",
       "                                                   test     0.192953   \n",
       "\n",
       "                                                                  f1  \\\n",
       "                                                                mean   \n",
       "model_name      optimizer class_weights batch_size dataset             \n",
       "e5              adamw     True          16         expert   0.662702   \n",
       "e5_lora_nli_all adamw     True          16         expert   0.648660   \n",
       "e5_lora_nli     adamw     True          16         expert   0.643199   \n",
       "e5_nli_all      adamw     True          16         test     0.629306   \n",
       "e5_nli          adamw     True          16         expert   0.628909   \n",
       "                                                   test     0.628682   \n",
       "e5_nli_all      adamw     True          16         expert   0.623191   \n",
       "e5              adamw     True          16         test     0.622947   \n",
       "roberta         adamw     True          16         expert   0.622677   \n",
       "                                                   test     0.618079   \n",
       "e5_lora_nli     adamw     True          16         test     0.617157   \n",
       "e5_lora         adamw     True          16         expert   0.616428   \n",
       "e5_lora_nli_all adamw     True          16         test     0.615646   \n",
       "e5_lora         adamw     True          16         test     0.612951   \n",
       "roberta_lora    adamw     True          16         test     0.604925   \n",
       "                                                   expert   0.602897   \n",
       "bert            adamw     True          16         test     0.596025   \n",
       "bert_lora       adamw     True          16         test     0.585215   \n",
       "bert            adamw     True          16         expert   0.519386   \n",
       "bert_lora       adamw     True          16         expert   0.467693   \n",
       "e5no_train      adamw     True          16         expert   0.312716   \n",
       "                                                   test     0.227925   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 std   \n",
       "model_name      optimizer class_weights batch_size dataset             \n",
       "e5              adamw     True          16         expert   0.015652   \n",
       "e5_lora_nli_all adamw     True          16         expert   0.008284   \n",
       "e5_lora_nli     adamw     True          16         expert   0.002336   \n",
       "e5_nli_all      adamw     True          16         test     0.000954   \n",
       "e5_nli          adamw     True          16         expert   0.016868   \n",
       "                                                   test     0.005161   \n",
       "e5_nli_all      adamw     True          16         expert   0.003573   \n",
       "e5              adamw     True          16         test     0.005132   \n",
       "roberta         adamw     True          16         expert   0.012752   \n",
       "                                                   test     0.004483   \n",
       "e5_lora_nli     adamw     True          16         test     0.004700   \n",
       "e5_lora         adamw     True          16         expert   0.019749   \n",
       "e5_lora_nli_all adamw     True          16         test     0.002134   \n",
       "e5_lora         adamw     True          16         test     0.005289   \n",
       "roberta_lora    adamw     True          16         test     0.003871   \n",
       "                                                   expert   0.029906   \n",
       "bert            adamw     True          16         test     0.003359   \n",
       "bert_lora       adamw     True          16         test     0.006003   \n",
       "bert            adamw     True          16         expert   0.012790   \n",
       "bert_lora       adamw     True          16         expert   0.031283   \n",
       "e5no_train      adamw     True          16         expert   0.129000   \n",
       "                                                   test     0.064906   \n",
       "\n",
       "                                                           precision  \\\n",
       "                                                                mean   \n",
       "model_name      optimizer class_weights batch_size dataset             \n",
       "e5              adamw     True          16         expert   0.673423   \n",
       "e5_lora_nli_all adamw     True          16         expert   0.650901   \n",
       "e5_lora_nli     adamw     True          16         expert   0.637387   \n",
       "e5_nli_all      adamw     True          16         test     0.823416   \n",
       "e5_nli          adamw     True          16         expert   0.637387   \n",
       "                                                   test     0.817133   \n",
       "e5_nli_all      adamw     True          16         expert   0.635135   \n",
       "e5              adamw     True          16         test     0.845898   \n",
       "roberta         adamw     True          16         expert   0.617117   \n",
       "                                                   test     0.844642   \n",
       "e5_lora_nli     adamw     True          16         test     0.853213   \n",
       "e5_lora         adamw     True          16         expert   0.599099   \n",
       "e5_lora_nli_all adamw     True          16         test     0.856579   \n",
       "e5_lora         adamw     True          16         test     0.855098   \n",
       "roberta_lora    adamw     True          16         test     0.834590   \n",
       "                                                   expert   0.572072   \n",
       "bert            adamw     True          16         test     0.818525   \n",
       "bert_lora       adamw     True          16         test     0.805825   \n",
       "bert            adamw     True          16         expert   0.452703   \n",
       "bert_lora       adamw     True          16         expert   0.389640   \n",
       "e5no_train      adamw     True          16         expert   0.459459   \n",
       "                                                   test     0.458625   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 std   \n",
       "model_name      optimizer class_weights batch_size dataset             \n",
       "e5              adamw     True          16         expert   0.034008   \n",
       "e5_lora_nli_all adamw     True          16         expert   0.014065   \n",
       "e5_lora_nli     adamw     True          16         expert   0.015604   \n",
       "e5_nli_all      adamw     True          16         test     0.003071   \n",
       "e5_nli          adamw     True          16         expert   0.020642   \n",
       "                                                   test     0.005402   \n",
       "e5_nli_all      adamw     True          16         expert   0.013514   \n",
       "e5              adamw     True          16         test     0.004862   \n",
       "roberta         adamw     True          16         expert   0.017004   \n",
       "                                                   test     0.003333   \n",
       "e5_lora_nli     adamw     True          16         test     0.003249   \n",
       "e5_lora         adamw     True          16         expert   0.020642   \n",
       "e5_lora_nli_all adamw     True          16         test     0.007124   \n",
       "e5_lora         adamw     True          16         test     0.004342   \n",
       "roberta_lora    adamw     True          16         test     0.005320   \n",
       "                                                   expert   0.040728   \n",
       "bert            adamw     True          16         test     0.003645   \n",
       "bert_lora       adamw     True          16         test     0.004271   \n",
       "bert            adamw     True          16         expert   0.011703   \n",
       "bert_lora       adamw     True          16         expert   0.023729   \n",
       "e5no_train      adamw     True          16         expert   0.470505   \n",
       "                                                   test     0.468987   \n",
       "\n",
       "                                                              recall  \\\n",
       "                                                                mean   \n",
       "model_name      optimizer class_weights batch_size dataset             \n",
       "e5              adamw     True          16         expert   0.652944   \n",
       "e5_lora_nli_all adamw     True          16         expert   0.646503   \n",
       "e5_lora_nli     adamw     True          16         expert   0.649695   \n",
       "e5_nli_all      adamw     True          16         test     0.509258   \n",
       "e5_nli          adamw     True          16         expert   0.620996   \n",
       "                                                   test     0.510866   \n",
       "e5_nli_all      adamw     True          16         expert   0.611957   \n",
       "e5              adamw     True          16         test     0.493044   \n",
       "roberta         adamw     True          16         expert   0.628421   \n",
       "                                                   test     0.487360   \n",
       "e5_lora_nli     adamw     True          16         test     0.483430   \n",
       "e5_lora         adamw     True          16         expert   0.634816   \n",
       "e5_lora_nli_all adamw     True          16         test     0.480503   \n",
       "e5_lora         adamw     True          16         test     0.477686   \n",
       "roberta_lora    adamw     True          16         test     0.474428   \n",
       "                                                   expert   0.637696   \n",
       "bert            adamw     True          16         test     0.468640   \n",
       "bert_lora       adamw     True          16         test     0.459442   \n",
       "bert            adamw     True          16         expert   0.609243   \n",
       "bert_lora       adamw     True          16         expert   0.584908   \n",
       "e5no_train      adamw     True          16         expert   0.336321   \n",
       "                                                   test     0.191148   \n",
       "\n",
       "                                                                      \\\n",
       "                                                                 std   \n",
       "model_name      optimizer class_weights batch_size dataset             \n",
       "e5              adamw     True          16         expert   0.006241   \n",
       "e5_lora_nli_all adamw     True          16         expert   0.002589   \n",
       "e5_lora_nli     adamw     True          16         expert   0.017795   \n",
       "e5_nli_all      adamw     True          16         test     0.001068   \n",
       "e5_nli          adamw     True          16         expert   0.021944   \n",
       "                                                   test     0.004707   \n",
       "e5_nli_all      adamw     True          16         expert   0.010366   \n",
       "e5              adamw     True          16         test     0.007000   \n",
       "roberta         adamw     True          16         expert   0.010305   \n",
       "                                                   test     0.004686   \n",
       "e5_lora_nli     adamw     True          16         test     0.005699   \n",
       "e5_lora         adamw     True          16         expert   0.019259   \n",
       "e5_lora_nli_all adamw     True          16         test     0.000717   \n",
       "e5_lora         adamw     True          16         test     0.005165   \n",
       "roberta_lora    adamw     True          16         test     0.006463   \n",
       "                                                   expert   0.016355   \n",
       "bert            adamw     True          16         test     0.003378   \n",
       "bert_lora       adamw     True          16         test     0.006016   \n",
       "bert            adamw     True          16         expert   0.017863   \n",
       "bert_lora       adamw     True          16         expert   0.044441   \n",
       "e5no_train      adamw     True          16         expert   0.047640   \n",
       "                                                   test     0.030123   \n",
       "\n",
       "                                                              f1_neg            \n",
       "                                                                mean       std  \n",
       "model_name      optimizer class_weights batch_size dataset                      \n",
       "e5              adamw     True          16         expert   0.855105  0.002429  \n",
       "e5_lora_nli_all adamw     True          16         expert   0.851592  0.001620  \n",
       "e5_lora_nli     adamw     True          16         expert   0.851845  0.005916  \n",
       "e5_nli_all      adamw     True          16         test     0.887340  0.000469  \n",
       "e5_nli          adamw     True          16         expert   0.840921  0.008852  \n",
       "                                                   test     0.888123  0.001786  \n",
       "e5_nli_all      adamw     True          16         expert   0.837210  0.004208  \n",
       "e5              adamw     True          16         test     0.879669  0.003309  \n",
       "roberta         adamw     True          16         expert   0.843399  0.004369  \n",
       "                                                   test     0.877106  0.002119  \n",
       "e5_lora_nli     adamw     True          16         test     0.874895  0.002762  \n",
       "e5_lora         adamw     True          16         expert   0.845113  0.007654  \n",
       "e5_lora_nli_all adamw     True          16         test     0.873353  0.000361  \n",
       "e5_lora         adamw     True          16         test     0.871999  0.002431  \n",
       "roberta_lora    adamw     True          16         test     0.871237  0.003453  \n",
       "                                                   expert   0.845267  0.007093  \n",
       "bert            adamw     True          16         test     0.869165  0.001596  \n",
       "bert_lora       adamw     True          16         test     0.865178  0.002841  \n",
       "bert            adamw     True          16         expert   0.832878  0.005128  \n",
       "bert_lora       adamw     True          16         expert   0.825648  0.011633  \n",
       "e5no_train      adamw     True          16         expert   0.516500  0.447986  \n",
       "                                                   test     0.550817  0.477551  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_results.groupby(['model_name', 'optimizer', 'class_weights', 'batch_size', 'dataset']).agg(['mean', 'std']).drop('seed', axis=1).sort_values(by=('f1', 'mean'), ascending=False)\n",
    "df.to_csv('../data/experiment_results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f23f5d6a-cecc-4344-ac5f-02b2f6f1e090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>class_weights</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bert</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bert_lora</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5_lora</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5_lora_nli</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5_lora_nli_all</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5_nli</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5_nli_all</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e5no_train</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">roberta</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">roberta_lora</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">adamw</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>expert</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            seed  \\\n",
       "                                                           count   \n",
       "model_name      optimizer class_weights batch_size dataset         \n",
       "bert            adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "bert_lora       adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "e5              adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "e5_lora         adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "e5_lora_nli     adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "e5_lora_nli_all adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "e5_nli          adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "e5_nli_all      adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "e5no_train      adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "roberta         adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "roberta_lora    adamw     True          16         expert      3   \n",
       "                                                   test        3   \n",
       "\n",
       "                                                           balanced_accuracy  \\\n",
       "                                                                       count   \n",
       "model_name      optimizer class_weights batch_size dataset                     \n",
       "bert            adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "bert_lora       adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "e5              adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "e5_lora         adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "e5_lora_nli     adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "e5_lora_nli_all adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "e5_nli          adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "e5_nli_all      adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "e5no_train      adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "roberta         adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "roberta_lora    adamw     True          16         expert                  3   \n",
       "                                                   test                    3   \n",
       "\n",
       "                                                              f1 precision  \\\n",
       "                                                           count     count   \n",
       "model_name      optimizer class_weights batch_size dataset                   \n",
       "bert            adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "bert_lora       adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "e5              adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "e5_lora         adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "e5_lora_nli     adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "e5_lora_nli_all adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "e5_nli          adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "e5_nli_all      adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "e5no_train      adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "roberta         adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "roberta_lora    adamw     True          16         expert      3         3   \n",
       "                                                   test        3         3   \n",
       "\n",
       "                                                           recall f1_neg  \n",
       "                                                            count  count  \n",
       "model_name      optimizer class_weights batch_size dataset                \n",
       "bert            adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "bert_lora       adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "e5              adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "e5_lora         adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "e5_lora_nli     adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "e5_lora_nli_all adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "e5_nli          adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "e5_nli_all      adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "e5no_train      adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "roberta         adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  \n",
       "roberta_lora    adamw     True          16         expert       3      3  \n",
       "                                                   test         3      3  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(['model_name', 'optimizer', 'class_weights', 'batch_size', 'dataset']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b02d8-2994-4b12-9a04-ab3c7de0c1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
